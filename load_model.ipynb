{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import Sastrawi\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deteksi retak permukaan jalan raya berbasis pengolahan citra dengan menggunakan kombinasi teknik thresholding, median filter dan morphological closing\n"
     ]
    }
   ],
   "source": [
    "kalimat = \"Deteksi Retak Permukaan Jalan Raya Berbasis Pengolahan Citra dengan Menggunakan Kombinasi Teknik Thresholding, Median Filter dan Morphological Closing\" \n",
    "lower_case = kalimat.lower()\n",
    "print (lower_case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deteksi retak permukaan jalan raya berbasis pengolahan citra dengan menggunakan kombinasi teknik thresholding median filter dan morphological closing\n"
     ]
    }
   ],
   "source": [
    "punctuation = lower_case.translate(str.maketrans('','',string.punctuation)).strip()\n",
    "print(punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['deteksi', 'retak', 'permukaan', 'jalan', 'raya', 'berbasis', 'pengolahan', 'citra', 'dengan', 'menggunakan', 'kombinasi', 'teknik', 'thresholding', 'median', 'filter', 'dan', 'morphological', 'closing']\n"
     ]
    }
   ],
   "source": [
    "tokenize = word_tokenize(punctuation)\n",
    "print(tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['deteksi', 'retak', 'permukaan', 'jalan', 'raya', 'berbasis', 'pengolahan', 'citra', 'menggunakan', 'kombinasi', 'teknik', 'thresholding', 'median', 'filter', 'morphological', 'closing']\n"
     ]
    }
   ],
   "source": [
    "factory = StopWordRemoverFactory()\n",
    "stopword = factory.create_stop_word_remover()\n",
    "hasil_stopword = []\n",
    "for i in tokenize:\n",
    "    word = stopword.remove(i)\n",
    "    if word !='':\n",
    "        hasil_stopword.append(word)\n",
    "print(hasil_stopword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['deteksi', 'retak', 'muka', 'jalan', 'raya', 'bas', 'olah', 'citra', 'guna', 'kombinasi', 'teknik', 'thresholding', 'median', 'filter', 'morphological', 'closing']\n"
     ]
    }
   ],
   "source": [
    "factory = StemmerFactory()\n",
    "stemmer = factory.create_stemmer()  \n",
    "hasil_stemming = [] \n",
    "for i in hasil_stopword:\n",
    "    word = stemmer.stem(i)\n",
    "    if word !='':\n",
    "        hasil_stemming.append(word) \n",
    "print(hasil_stemming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['closing morphological filter median thresholding teknik kombinasi guna citra olah bas raya jalan muka retak deteksi']\n"
     ]
    }
   ],
   "source": [
    "text_final=[' '.join(reversed(hasil_stemming))]\n",
    "print(text_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load TFIDF model\n",
    "import pickle\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer\n",
    "transformer = TfidfTransformer()\n",
    "loaded_vec = CountVectorizer(decode_error=\"replace\",vocabulary=pickle.load(open(\"TFIDF_Judul.pkl\", \"rb\")))\n",
    "tfidf = transformer.fit_transform(loaded_vec.fit_transform(text_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 1506)\t0.30151134457776363\n",
      "  (0, 1014)\t0.30151134457776363\n",
      "  (0, 947)\t0.30151134457776363\n",
      "  (0, 872)\t0.30151134457776363\n",
      "  (0, 723)\t0.30151134457776363\n",
      "  (0, 635)\t0.30151134457776363\n",
      "  (0, 521)\t0.30151134457776363\n",
      "  (0, 440)\t0.30151134457776363\n",
      "  (0, 353)\t0.30151134457776363\n",
      "  (0, 263)\t0.30151134457776363\n",
      "  (0, 149)\t0.30151134457776363\n"
     ]
    }
   ],
   "source": [
    "print (tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load SVM model\n",
    "loaded_SVM_model = pickle.load(open('SVM_model.sav', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n"
     ]
    }
   ],
   "source": [
    "print (loaded_SVM_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_SVM_model.predict(tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load SVM  LINIER model\n",
    "loaded_SVMlinier_model = pickle.load(open('SVMLinier_model.sav', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "          verbose=0)\n"
     ]
    }
   ],
   "source": [
    "print (loaded_SVMlinier_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_SVMlinier_model.predict(tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load SVM  POLYNOMIAL model\n",
    "loaded_SVMpolynomial_model = pickle.load(open('SVMPolynomial_model.sav', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='poly', max_iter=-1, probability=False, random_state=None,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n"
     ]
    }
   ],
   "source": [
    "print (loaded_SVMpolynomial_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_SVMpolynomial_model.predict(tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load SVM RBF model\n",
    "loaded_SVMrbf_model = pickle.load(open('SVMRBF_model.sav', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma=0.7, kernel='rbf',\n",
      "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "    tol=0.001, verbose=False)\n"
     ]
    }
   ],
   "source": [
    "print (loaded_SVMrbf_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_SVMrbf_model.predict(tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
